<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="icon" href="/images/logo.png" type="image/png">
  <link rel="shortcut icon" href="/images/logo.png" type="image/png">
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Jinnan Chen</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      font-family: Arial, sans-serif;
      line-height: 1.6;
      color: #333;
      background-color: #ffffff;
    }

    .main-container {
      display: flex;
      flex-wrap: wrap;
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
      background-color: #fff;
      /* Removed box-shadow to eliminate borders */
    }

    .profile-container {
      flex: 0 0 25%;
      padding: 20px;
      background-color: #ffffff;
      border-radius: 5px;
      margin-right: 20px;
      margin-bottom: 20px;
      align-self: flex-start;
      margin-top: 40px;
    }

    .profile-image {
      width: 100%;
      max-width: 250px;
      margin-bottom: 15px;
      border-radius: 5px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }

    .profile-address {
      margin-top: 15px;
      font-size: 14px;
    }

    .content-container {
      flex: 1;
      min-width: 60%;
      padding-top: 20px;
      align-self: flex-start;
    }

    .max-width-container {
      max-width: 900px;
      margin: 0 auto; 
      padding: 0 20px;
    }

    .publication-item {
      display: flex;
      margin-bottom: 30px;
      align-items: center;
    }

    .publication-image {
      flex: 0 0 280px;
      margin-right: 30px;
    }

    .publication-image img, 
    .publication-image video {
      width: 100%;
      border-radius: 5px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }

    .publication-content {
      flex: 1;
    }

    @media (max-width: 768px) {
      .main-container {
        flex-direction: column;
      }
      
      .profile-container {
        flex: 0 0 100%;
        margin-right: 0;
      }
      
      .publication-item {
        flex-direction: column;
      }
      
      .publication-image {
        flex: 0 0 100%;
        margin-bottom: 15px;
        margin-right: 0;
      }
    }

    @media (max-width: 576px) {
      .publication-content {
        font-size: 14px;
      }
      
      .section-header {
        font-size: 20px;
      }
      
      .publication-image {
        max-width: 100%;
      }
    }

    .section-header {
      margin-top: 40px;
      border-bottom: 1px solid #eee;
      padding-bottom: 10px;
    }

    .news-list, .awards-list, .teaching-list, .reviewer-list {
      margin-left: 20px;
    }

    /* Social media icons */
    .social-icons {
      display: flex;
      flex-direction: column;
      margin-top: 20px;
    }

    .social-icons a {
      display: flex;
      align-items: center;
      margin-bottom: 10px;
      text-decoration: none;
      color: #333;
      transition: color 0.3s ease;
    }

    .social-icons a:hover {
      color: #0366d6;
    }

    .social-icons i {
      width: 20px;
      margin-right: 10px;
      font-size: 1.2rem;
    }
    
    /* Job market highlight */
    .job-market {
      background-color: #ffffff;
      padding: 15px;
      border-radius: 5px;
      margin: 20px 0;
    }
  </style>
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
  <div class="main-container">
    <!-- Profile Section -->
    <div class="profile-container">
      <img src="profile.png" alt="Jinnan Chen Profile" class="profile-image">
      <div class="profile-address">
        <p><i class="fas fa-map-marker-alt"></i> <span style="font-size: 16px;">Singapore</span></p>
      </div>
      
      <!-- Social Media Links -->
      <div class="social-icons">
        <a href="mailto:jinnancv@gmail.com" title="Email">
          <i class="fas fa-envelope"></i> Email
        </a>
        <a href="https://www.linkedin.com/in/jinnan-chen-146b2317b/" title="LinkedIn">
          <i class="fab fa-linkedin"></i> LinkedIn
        </a>
        <a href="https://x.com/jinmelo7" title="X (Twitter)">
          <i class="fab fa-twitter"></i> X (Twitter)
        </a>
        <a href="https://scholar.google.com.sg/citations?user=7idMjaQAAAAJ&hl=zh-CN" title="Google Scholar">
          <i class="fas fa-graduation-cap"></i> Google Scholar
        </a>
        <a href="https://github.com/jinnan-chen" title="GitHub">
          <i class="fab fa-github"></i> GitHub
        </a>
      </div>
    </div>

    <!-- Content Section -->
    <div class="content-container">
      <div class="max-width-container">
        <h1 style="font-size: 32px; font-weight: 700; margin-top: 40px; border-bottom: 1px solid #eee; padding-bottom: 10px;" id="about">Jinnan Chen</h1>
        <p>
          I'm currently a Ph.D. candidate at NUS School of Computing, supervised by Prof <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>. 
          I received my B.E. degree from Wuhan University and MEng degree from Nanyang Technology University with a GPA of 5.0/5.0. During my master's study, I was supervised by Prof <a href="https://personal.ntu.edu.sg/exdjiang/">Jiang Xudong</a> and Dr <a href="https://person.zju.edu.cn/zq">Qian Zheng</a>.
        </p>
        <p>
          Currently, my research interests are mainly in Computer Vision and Generative Models, including <strong>Reconstruction</strong> (Neural Fields & 3DGS), <strong>Animation</strong> (Skinning & Rigging), <strong>Generation</strong> (Diffusion & AR).
        </p>
        
        <div class="job-market">
          <span style="color: orange; font-weight: bold;">I'm on the job market and looking for a Research Scientist/Engineer position. Feel free to reach out if you have any openings!</span>
        </div>
        
        <h2 class="section-header" id="news">News</h2>
        <div class="news-list">
          <ul>
            <li><strong>ðŸŽ‰ [05.2025]</strong> I was selected as Outstanding Reviewer in CVPR 2025</li>
            <li><strong>ðŸŽ‰ [04.2025]</strong> Our MAR-3D is selected as <strong>Highlight</strong> in CVPR 2025 (Top 3% of submissions)</li>
            <li><strong>ðŸŽ‰ [02.2025]</strong> Two papers are accepted in CVPR 2025</li>
            <li><strong>ðŸŽ‰ [01.2025]</strong> One paper is accepted in ICLR 2025</li>
            <li><strong>ðŸŽ‰ [12.2024]</strong> One paper is accepted in AAAI 2025</li>
            <li><strong>ðŸŽ‰ [10.2024]</strong> One paper is accepted in WACV 2025</li>
            <li><strong>ðŸŽ‰ [06.2023]</strong> One paper is accepted in ICCV 2023</li>
            <li><strong>ðŸŽ‰ [02.2021]</strong> One paper is accepted in CVPR 2021</li>
            <li><strong>ðŸŽ‰ [02.2020]</strong> One paper is accepted in CVPR 2020</li>
          </ul>
        </div>
        
        <h2 class="section-header" id="publications">Publications</h2>

        <article class="publication-item">
          <div class="publication-image">
            <img src="images/Teaser_Muma.png" alt="MuMA: 3D PBR Texturing via Multi-Channel Multi-View Generation">
          </div>
          <div class="publication-content">
            <strong>MuMA: 3D PBR Texturing via Multi-Channel Multi-View Generation and Agentic Post-Processing.</strong> <a href="https://arxiv.org/abs/2503.18461">[arXiv]</a><br>
            Lingting Zhu, Jingrui Ye, Runze Zhang, Zeyu Hu, Yingda Yin, Lanjiong Li, <strong>Jinnan Chen</strong>, Shengju Qian, Xin Wang, Qingmin Liao, Lequan Yu<br>
            <em>Arxiv 2025</em>
          </div>
        </article>


        <article class="publication-item">
          <div class="publication-image">
            <img src="images/human-motion.gif" alt="Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference Optimization">
          </div>
          <div class="publication-content">
            <strong>Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference Optimization.</strong> <a href="https://arxiv.org/abs/2506.11430">[arXiv]</a><a href="https://autoconnectrig.github.io/">[page]</a><br>
            Jingfeng Guo*, Jian Liu*, <strong>Jinnan Chen<strong>â€ , Shiwei Mao, Changrong Hu, Puhua Jiang, Junlin Yu, Jing Xu, Qi Liuâ€ , Lixin Xu, Zhuo Chen, Chunchao Guo<br>
            <em>Arxiv 2025</em>
          </div>
        </article>
        
        <article class="publication-item">
          <div class="publication-image">
            <video width="100%" autoplay loop muted playsinline>
              <source src="videos/mar-3d.mov" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="publication-content">
            <strong>MAR-3D: Progressive Masked Auto-regressor for High-Resolution 3D Generation.</strong> <a href="https://arxiv.org/abs/2503.20519">[arXiv]</a> <a href="https://jinnan-chen.github.io/projects/MAR-3D/">[page]</a><br>
            <strong>Jinnan Chen</strong>, Lingting Zhu, Zeyu Hu, Shengju Qian, Yugang Chen, Xin Wang, Gim Hee Lee<br>
            <em>IEEE Conference on Computer Vision and Pattern Recognitionï¼ˆ<strong>CVPR</strong>ï¼‰2025 Highlight</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <video width="100%" autoplay loop muted playsinline>
              <source src="videos/close.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="publication-content">
            <strong>Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning.</strong> <a href="https://www.buzhenhuang.com/publications/papers/CVPR2025-CloseApp.pdf">[paper]</a> <a href="https://www.buzhenhuang.com/works/CloseApp.html">[page]</a><br>
            Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, <strong>Jinnan Chen</strong>, Yangang Wang, Gim Hee Lee<br>
            <em>IEEE Conference on Computer Vision and Pattern Recognitionï¼ˆ<strong>CVPR</strong>ï¼‰2025</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <video width="100%" autoplay loop muted playsinline>
              <source src="videos/hgm.mov" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="publication-content">
            <strong>Generalizable Human Gaussians from Single-View Image.</strong> <a href="https://arxiv.org/abs/2406.06050">[arXiv]</a> <a href="https://jinnan-chen.github.io/projects/HGM/">[page]</a><br>
            <strong>Jinnan Chen</strong>, Chen Li, Jianfeng Zhang, Lingting Zhu, Buzhen Huang, Hanlin Chen, Gim Hee Lee<br>
            <em>The International Conference on Learning Representationsï¼ˆ<strong>ICLR</strong>ï¼‰2025</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <img src="images/teaser-lig.png" alt="Large Images are Gaussians: Levels of 2D Gaussian Splatting">
          </div>
          <div class="publication-content">
            <strong>Large Images are Gaussians: High-quality Large Image Representation with Levels of 2D Gaussian Splatting.</strong> <a href="https://arxiv.org/abs/2502.09039">[arXiv]</a> <a href="https://github.com/HKU-MedAI/LIG">[code]</a><br>
            Lingting Zhu, Guying Lin, <strong>Jinnan Chen</strong>, Xinjie Zhang, Zhenchao Jin, Zhao Wang, Lequan Yu<br>
            <em>The Association for the Advancement of Artificial Intelligence (<strong>AAAI</strong>) 2025</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <video width="100%" autoplay loop muted playsinline>
              <source src="videos/dihur.mov" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="publication-content">
            <strong>DiHuR: Diffusion-Guided Generalizable Human Reconstruction.</strong> <a href="https://arxiv.org/abs/2411.11903">[arXiv]</a><br>
            <strong>Jinnan Chen</strong>, Chen Li, Gim Hee Lee<br>
            <em>IEEE/CVF Winter Conference (<strong>WACV</strong>) 2025</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <img src="images/ws3dpt.png" alt="Weakly-supervised 3D Pose Transfer with Keypoints">
          </div>
          <div class="publication-content">
            <strong>Weakly-supervised 3D Pose Transfer with Keypoints.</strong> <a href="https://arxiv.org/abs/2307.13459">[arXiv]</a> <a href="https://jinnan-chen.github.io/ws3dpt/">[page]</a> <a href="https://github.com/jinnan-chen/3D-Pose-Transfer">[code]</a><br>
            <strong>Jinnan Chen</strong>, Chen Li, Gim Hee Lee<br>
            <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>) 2023</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <img src="images/teaser_absorption.png" alt="Single image reflection removal with absorption effect">
          </div>
          <div class="publication-content">
            <strong>Single image reflection removal with absorption effect.</strong> <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Single_Image_Reflection_Removal_With_Absorption_Effect_CVPR_2021_paper.html">[paper]</a> <a href="https://github.com/q-zh/absorption">[code]</a><br>
            Qian Zheng, Boxin Shi, <strong>Jinnan Chen</strong>, Xudong Jiang, Ling-Yu Duan, Alex C. Kot<br>
            <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>) 2021</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <img src="images/teaser_distillation.png" alt="Feature distillation with guided adversarial contrastive learning">
          </div>
          <div class="publication-content">
            <strong>Feature distillation with guided adversarial contrastive learning.</strong> <a href="https://arxiv.org/abs/2009.09922">[arXiv]</a><br>
            Tao Bai, <strong>Jinnan Chen</strong>, Jun Zhao, Bihan Wen, Xudong Jiang, Alex Kot<br>
            <em>Arxiv 2020</em>
          </div>
        </article>

        <article class="publication-item">
          <div class="publication-image">
            <img src="images/teaser_glass.png" alt="What does plate glass reveal about camera calibration?">
          </div>
          <div class="publication-content">
            <strong>What does plate glass reveal about camera calibration?</strong> <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Zheng_What_Does_Plate_Glass_Reveal_About_Camera_Calibration_CVPR_2020_paper.html">[paper]</a> <a href="https://github.com/q-zh/GlassCalibration">[code]</a><br>
            Qian Zheng, <strong>Jinnan Chen</strong>, Zhan Lu, Boxin Shi, Xudong Jiang, Kim-Hui Yap, Ling-Yu Duan, Alex C. Kot<br>
            <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>) 2020</em>
          </div>
        </article>
        
        <h2 class="section-header" id="teaching">Teaching</h2>
        <div class="teaching-list">
          <ul>
            <li>[2022] CS5340 Uncertainty Modelling in AI, National University of Singapore</li>
            <li>[2022] CS5477 3D Computer Vision, National University of Singapore</li>
          </ul>
        </div>
        
        <h2 class="section-header" id="service">Academic Services (Reviewer)</h2>
        <div class="reviewer-list">
          <ul>
            <li>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024, 2025</li>
            <li>IEEE/CVF International Conference on Computer Vision (ICCV) 2025</li>
            <li>International Conference on Machine Learning (ICML) 2025</li>
            <li>Conference on Neural Information Processing Systems (NeurIPS) 2024, 2025</li>
            <li>International Conference on Learning Representations (ICLR) 2025</li>
            <li>International Conference on Artificial Intelligence and Statistics (AISTATS) 2025</li>
          </ul>
        </div>
      <h2 class="section-header" id="awards">Awards</h2>
<div class="awards-list">
  <ul>
    <li>Wuhan University Excellent Student</li>
    <li>NUS Research Scholarship</li>
    <li>NUS Research Achievement</li>
    <li>CVPR Outstanding Reviewer 2025</li>
  </ul>
</div>


<div style="display: flex; justify-content: flex-start; margin-top: 40px; margin-bottom: 40px;">
  <a href="https://info.flagcounter.com/HQ0J"><img src="https://s11.flagcounter.com/count2/HQ0J/bg_FFFFFF/txt_000000/border_CCCCCC/columns_5/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
</div>

      </div>
    </div>
  </div>
</body>
</html>
